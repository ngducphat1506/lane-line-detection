import streamlit as st
import numpy as np
import cv2
import os
import tempfile
from moviepy.editor import VideoFileClip
#thay ƒë·ªïi th·ª≠ th√¥i
class LaneDetector:
    def __init__(self, config=None):
        # C·∫•u h√¨nh m·∫∑c ƒë·ªãnh
        self.config = {
            'kernel_size': 5,
            'canny_low_threshold': 50,
            'canny_high_threshold': 150,
            'hough_threshold': 20,
            'min_line_length': 20,
            'max_line_gap': 300,
            'line_color': [255, 0, 0],
            'line_thickness': 12
        }
        
        # C·∫≠p nh·∫≠t c·∫•u h√¨nh t·ª´ tham s·ªë
        if config:
            self.config.update(config)
        
        # D·ªØ li·ªáu ƒë·ªÉ l√†m m·ªãn l√†n ƒë∆∞·ªùng
        self.left_line_history = []
        self.right_line_history = []
        self.history_size = 10
        
    def gray_scale(self, image):
        """Chuy·ªÉn ƒë·ªïi ·∫£nh sang thang ƒë·ªô x√°m"""
        return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    def canny_detector(self, image):
        """√Åp d·ª•ng Canny detector cho ·∫£nh"""
        return cv2.Canny(
            image, 
            self.config['canny_low_threshold'], 
            self.config['canny_high_threshold']
        )
    
    def gaussian_smoothing(self, image, kernel_size=None):
        """√Åp d·ª•ng Gaussian Blur cho ·∫£nh"""
        if kernel_size is None:
            kernel_size = self.config['kernel_size']
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    
    def region_selection(self, image):
        """Ch·ªçn v√πng quan t√¢m trong ·∫£nh"""
        mask = np.zeros_like(image)
        if len(image.shape) > 2:
            channel_count = image.shape[2]
            ignore_mask_color = (255,) * channel_count
        else:
            ignore_mask_color = 255
            
        rows, cols = image.shape[:2]
        bottom_left = [cols * 0.1, rows * 0.95]
        top_left = [cols * 0.4, rows * 0.6]
        bottom_right = [cols * 0.9, rows * 0.95]
        top_right = [cols * 0.6, rows * 0.6]
        vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)
        cv2.fillPoly(mask, vertices, ignore_mask_color)
        masked_image = cv2.bitwise_and(image, mask)
        return masked_image
    
    def hough_transform(self, image):
        """√Åp d·ª•ng Hough Transform ƒë·ªÉ t√¨m ƒë∆∞·ªùng th·∫≥ng"""
        return cv2.HoughLinesP(
            image, 
            1,  # rho
            np.pi/180,  # theta
            self.config['hough_threshold'], 
            minLineLength=self.config['min_line_length'], 
            maxLineGap=self.config['max_line_gap']
        )
    
    def average_slope_intercept(self, lines):
        """T√¨m c√°c ƒë∆∞·ªùng th·∫≥ng trung b√¨nh c·ªßa l√†n ƒë∆∞·ªùng b√™n tr√°i v√† b√™n ph·∫£i"""
        left_lines = []
        left_weights = []
        right_lines = []
        right_weights = []
        
        if lines is None:
            return None, None
        
        for line in lines:
            for x1, y1, x2, y2 in line:
                if x1 == x2:
                    continue
                slope = (y2 - y1) / (x2 - x1)
                intercept = y1 - (slope * x1)
                length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))
                if slope < 0:
                    left_lines.append((slope, intercept))
                    left_weights.append(length)
                else:
                    right_lines.append((slope, intercept))
                    right_weights.append(length)
                    
        left_lane = np.dot(left_weights, left_lines) / np.sum(left_weights) if len(left_weights) > 0 else None
        right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None
        
        return left_lane, right_lane
    
    def smooth_lanes(self, left_lane, right_lane):
        """L√†m m·ªãn l√†n ƒë∆∞·ªùng qua nhi·ªÅu khung h√¨nh"""
        # Th√™m l√†n ƒë∆∞·ªùng m·ªõi v√†o l·ªãch s·ª≠
        if left_lane is not None:
            self.left_line_history.append(left_lane)
            if len(self.left_line_history) > self.history_size:
                self.left_line_history.pop(0)
        
        if right_lane is not None:
            self.right_line_history.append(right_lane)
            if len(self.right_line_history) > self.history_size:
                self.right_line_history.pop(0)
        
        # L·∫•y gi√° tr·ªã trung b√¨nh t·ª´ l·ªãch s·ª≠
        left_avg = np.mean(self.left_line_history, axis=0) if self.left_line_history else None
        right_avg = np.mean(self.right_line_history, axis=0) if self.right_line_history else None
        
        return left_avg, right_avg
    
    def pixel_points(self, y1, y2, line):
        """Chuy·ªÉn ƒë·ªïi slope v√† intercept th√†nh c√°c ƒëi·ªÉm pixel"""
        if line is None:
            return None
        slope, intercept = line
        x1 = int((y1 - intercept)/slope)
        x2 = int((y2 - intercept)/slope)
        y1 = int(y1)
        y2 = int(y2)
        return ((x1, y1), (x2, y2))
    
    def lane_lines(self, image, lines):
        """T·∫°o c√°c ƒë∆∞·ªùng th·∫≥ng l√†n ƒë∆∞·ªùng ƒë·∫ßy ƒë·ªß t·ª´ c√°c ƒëi·ªÉm pixel"""
        left_lane, right_lane = self.average_slope_intercept(lines)
        
        # L√†m m·ªãn l√†n ƒë∆∞·ªùng qua nhi·ªÅu khung h√¨nh
        left_lane, right_lane = self.smooth_lanes(left_lane, right_lane)
        
        y1 = image.shape[0]
        y2 = y1 * 0.6
        left_line = self.pixel_points(y1, y2, left_lane)
        right_line = self.pixel_points(y1, y2, right_lane)
        return left_line, right_line
    
    def draw_lane_lines(self, image, lines):
        """V·∫Ω c√°c ƒë∆∞·ªùng l√†n tr√™n ·∫£nh ƒë·∫ßu v√†o"""
        line_image = np.zeros_like(image)
        for line in lines:
            if line is not None:
                cv2.line(
                    line_image, 
                    *line, 
                    self.config['line_color'], 
                    self.config['line_thickness']
                )
        return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)
    
    def HSL_color_selection(self, image):
        """√Åp d·ª•ng l·ª±a ch·ªçn m√†u HSL ƒë·ªÉ l√†m n·ªïi b·∫≠t ƒë∆∞·ªùng k·∫ª l√†n ƒë∆∞·ªùng tr·∫Øng v√† v√†ng"""
        # Chuy·ªÉn ƒë·ªïi sang HSL
        converted_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)
        
        # M·∫∑t n·∫° m√†u tr·∫Øng
        lower_threshold = np.uint8([0, 200, 0])
        upper_threshold = np.uint8([255, 255, 255])
        white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)
        
        # M·∫∑t n·∫° m√†u v√†ng
        lower_threshold = np.uint8([10, 0, 100])
        upper_threshold = np.uint8([40, 255, 255])
        yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)
        
        # K·∫øt h·ª£p c√°c m·∫∑t n·∫°
        mask = cv2.bitwise_or(white_mask, yellow_mask)
        masked_image = cv2.bitwise_and(image, image, mask=mask)
        
        return masked_image
    
    def process_frame(self, image, return_steps=False):
        """X·ª≠ l√Ω khung h√¨nh ƒë·ªÉ ph√°t hi·ªán l√†n ƒë∆∞·ªùng"""
        # X·ª≠ l√Ω ·∫£nh
        color_select = self.HSL_color_selection(image)
        gray = self.gray_scale(color_select)
        smooth = self.gaussian_smoothing(gray)
        edges = self.canny_detector(smooth)
        region = self.region_selection(edges)
        hough = self.hough_transform(region)
        result = self.draw_lane_lines(image, self.lane_lines(image, hough))
        
        if return_steps:
            steps = {
                'original': image,
                'color_select': color_select,
                'edges': cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB) if len(edges.shape) < 3 else edges,
                'region': cv2.cvtColor(region, cv2.COLOR_GRAY2RGB) if len(region.shape) < 3 else region,
                'result': result
            }
            return steps
        
        return result

def process_video(uploaded_video, config=None, progress_callback=None):
    """X·ª≠ l√Ω video v·ªõi detector v√† tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n t·ªõi video k·∫øt qu·∫£"""
    if uploaded_video is None:
        return None
    
    # L∆∞u video t·∫°m
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    tfile.write(uploaded_video.read())
    input_filename = tfile.name
    
    # T·∫°o t√™n file ƒë·∫ßu ra
    output_filename = f"{input_filename}_processed.mp4"
    
    # T·∫°o detector
    detector = LaneDetector(config)
    
    # X·ª≠ l√Ω video
    try:
        video_clip = VideoFileClip(input_filename)
        
        # ƒê·ªãnh nghƒ©a wrapper ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô
        def process_frame_with_progress(frame, frame_index=None, total_frames=None):
            if progress_callback and frame_index is not None and total_frames is not None:
                progress = int(100 * frame_index / total_frames)
                progress_callback(progress)
            return detector.process_frame(frame)
        
        # X·ª≠ l√Ω m·ªói khung h√¨nh v·ªõi ti·∫øn ƒë·ªô
        frames = list(video_clip.iter_frames())
        total_frames = len(frames)
        
        processed_frames = []
        for i, frame in enumerate(frames):
            processed_frame = process_frame_with_progress(frame, i, total_frames)
            processed_frames.append(processed_frame)
        
        # T·∫°o clip m·ªõi t·ª´ c√°c khung h√¨nh ƒë√£ x·ª≠ l√Ω
        from moviepy.video.io.ImageSequenceClip import ImageSequenceClip
        processed_clip = ImageSequenceClip(processed_frames, fps=video_clip.fps)
        
        # L∆∞u video k·∫øt qu·∫£
        processed_clip.write_videofile(output_filename, audio=False)
        
        # ƒê√≥ng v√† x√≥a file t·∫°m sau khi ƒë√£ x·ª≠ l√Ω xong
        video_clip.close()
        try:
            if os.path.exists(input_filename):
                os.unlink(input_filename)
        except PermissionError:
            # B·ªè qua l·ªói khi kh√¥ng th·ªÉ x√≥a file do file ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng
            st.warning("Kh√¥ng th·ªÉ x√≥a file t·∫°m. File s·∫Ω ƒë∆∞·ª£c x√≥a khi ·ª©ng d·ª•ng ƒë√≥ng.")
            pass
            
        return output_filename
    
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω video: {str(e)}")
        # C·ªë g·∫Øng x√≥a file t·∫°m trong tr∆∞·ªùng h·ª£p c√≥ l·ªói
        try:
            if os.path.exists(input_filename):
                os.unlink(input_filename)
        except:
            pass
        return None

def main():
    st.set_page_config(
        page_title="Ph√°t hi·ªán l√†n ƒë∆∞·ªùng",
        page_icon="üöó",
        layout="wide"
    )
    
    st.title("üöó ·ª®ng d·ª•ng ph√°t hi·ªán l√†n ƒë∆∞·ªùng")
    
    # Sidebar cho c·∫•u h√¨nh
    st.sidebar.header("C·∫•u h√¨nh ph√°t hi·ªán l√†n ƒë∆∞·ªùng")
    
    # CSS cho tooltip
    st.markdown("""
    <style>
    .tooltip {
        position: relative;
        display: inline-block;
        cursor: pointer;
    }
    .tooltip .tooltiptext {
        visibility: hidden;
        width: 250px;
        background-color: #555;
        color: #fff;
        text-align: left;
        border-radius: 6px;
        padding: 8px;
        position: absolute;
        z-index: 1;
        top: -5px;
        left: 125%;
        margin-left: 0px;
        opacity: 0;
        transition: opacity 0.3s;
        font-size: 14px;
    }
    .tooltip .tooltiptext::after {
        content: "";
        position: absolute;
        top: 15px;
        right: 100%;
        margin-top: -5px;
        border-width: 5px;
        border-style: solid;
        border-color: transparent #555 transparent transparent;
    }
    .tooltip:hover .tooltiptext {
        visibility: visible;
        opacity: 1;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # H√†m t·∫°o tooltip
    def create_tooltip(label, description):
        return f"""
        <div class="tooltip">{label} ‚ÑπÔ∏è
            <span class="tooltiptext">{description}</span>
        </div>
        """
    
    # K√≠ch th∆∞·ªõc kernel Gaussian v·ªõi tooltip
    st.sidebar.markdown(create_tooltip(
        "K√≠ch th∆∞·ªõc kernel Gaussian",
        "ƒêi·ªÅu ch·ªânh ƒë·ªô m·ªãn c·ªßa h√¨nh ·∫£nh. Gi√° tr·ªã cao h∆°n s·∫Ω l√†m m·ªù h√¨nh ·∫£nh nhi·ªÅu h∆°n, gi√∫p gi·∫£m nhi·ªÖu nh∆∞ng c√≥ th·ªÉ l√†m m·∫•t chi ti·∫øt."
    ), unsafe_allow_html=True)
    kernel_size = st.sidebar.slider("", 3, 15, 5, 2, key="kernel_size")
    
    # Ng∆∞·ª°ng d∆∞·ªõi Canny v·ªõi tooltip
    st.sidebar.markdown(create_tooltip(
        "Ng∆∞·ª°ng d∆∞·ªõi Canny",
        "Ng∆∞·ª°ng d∆∞·ªõi cho thu·∫≠t to√°n Canny edge detection. C√°c c·∫°nh c√≥ gradient th·∫•p h∆°n gi√° tr·ªã n√†y s·∫Ω b·ªã lo·∫°i b·ªè."
    ), unsafe_allow_html=True)
    canny_low = st.sidebar.slider("", 30, 100, 50, 5, key="canny_low")
    
    # Ng∆∞·ª°ng tr√™n Canny v·ªõi tooltip
    st.sidebar.markdown(create_tooltip(
        "Ng∆∞·ª°ng tr√™n Canny",
        "Ng∆∞·ª°ng tr√™n cho thu·∫≠t to√°n Canny edge detection. C√°c c·∫°nh c√≥ gradient cao h∆°n gi√° tr·ªã n√†y s·∫Ω lu√¥n ƒë∆∞·ª£c gi·ªØ l·∫°i."
    ), unsafe_allow_html=True)
    canny_high = st.sidebar.slider("", 100, 200, 150, 5, key="canny_high")
    
    # Ng∆∞·ª°ng Hough Transform v·ªõi tooltip
    st.sidebar.markdown(create_tooltip(
        "Ng∆∞·ª°ng Hough Transform",
        "S·ªë l∆∞·ª£ng ƒëi·ªÉm t·ªëi thi·ªÉu ƒë·ªÉ x√°c ƒë·ªãnh m·ªôt ƒë∆∞·ªùng th·∫≥ng. Gi√° tr·ªã cao h∆°n s·∫Ω gi·∫£m s·ªë l∆∞·ª£ng ƒë∆∞·ªùng th·∫≥ng ph√°t hi·ªán ƒë∆∞·ª£c nh∆∞ng tƒÉng ƒë·ªô tin c·∫≠y."
    ), unsafe_allow_html=True)
    hough_threshold = st.sidebar.slider("", 10, 50, 20, 1, key="hough_threshold")
    
    # ƒê·ªô d√†y ƒë∆∞·ªùng k·∫ª v·ªõi tooltip
    st.sidebar.markdown(create_tooltip(
        "ƒê·ªô d√†y ƒë∆∞·ªùng k·∫ª",
        "ƒê·ªô d√†y c·ªßa ƒë∆∞·ªùng k·∫ª l√†n ƒë∆∞·ªùng tr√™n h√¨nh ·∫£nh k·∫øt qu·∫£."
    ), unsafe_allow_html=True)
    line_thickness = st.sidebar.slider("", 5, 20, 12, 1, key="line_thickness")
    
    # M√†u ƒë∆∞·ªùng k·∫ª v·ªõi tooltip
    st.sidebar.markdown(create_tooltip(
        "M√†u ƒë∆∞·ªùng k·∫ª",
        "M√†u s·∫Øc c·ªßa ƒë∆∞·ªùng k·∫ª l√†n ƒë∆∞·ªùng tr√™n h√¨nh ·∫£nh k·∫øt qu·∫£."
    ), unsafe_allow_html=True)
    color_options = {
        "ƒê·ªè": [255, 0, 0],
        "Xanh l√°": [0, 255, 0],
        "Xanh d∆∞∆°ng": [0, 0, 255],
        "V√†ng": [255, 255, 0]
    }
    line_color_name = st.sidebar.selectbox("", list(color_options.keys()), index=0, key="line_color")
    line_color = color_options[line_color_name]
    
    # C·∫•u h√¨nh detector
    config = {
        'kernel_size': kernel_size,
        'canny_low_threshold': canny_low,
        'canny_high_threshold': canny_high,
        'hough_threshold': hough_threshold,
        'line_color': line_color,
        'line_thickness': line_thickness
    }
    
    # T·∫°o hai c·ªôt ch√≠nh
    col1, col2 = st.columns(2)
    
    with col1:
        st.header("ƒê·∫ßu v√†o")
        
        # Upload video
        uploaded_video = st.file_uploader("T·∫£i l√™n video", type=['mp4', 'avi', 'mov'])
        
        if uploaded_video is not None:
            st.video(uploaded_video)
            
            # T·∫°o n√∫t x·ª≠ l√Ω
            process_button = st.button("X·ª≠ l√Ω video")
            
            if process_button:
                # Hi·ªÉn th·ªã thanh ti·∫øn ƒë·ªô
                progress_bar = st.progress(0)
                
                def update_progress(progress):
                    progress_bar.progress(progress)
                
                with st.spinner("ƒêang x·ª≠ l√Ω video..."):
                    # X·ª≠ l√Ω video
                    processed_video_path = process_video(uploaded_video, config, update_progress)
                    
                    if processed_video_path:
                        # L∆∞u ƒë∆∞·ªùng d·∫´n v√†o session state ƒë·ªÉ c√≥ th·ªÉ hi·ªÉn th·ªã ·ªü c·ªôt b√™n ph·∫£i
                        st.session_state.processed_video_path = processed_video_path
                        st.success("X·ª≠ l√Ω video th√†nh c√¥ng!")
                    else:
                        st.error("Kh√¥ng th·ªÉ x·ª≠ l√Ω video.")
        
        # Th·ª≠ v·ªõi v√≠ d·ª•
        st.header("Ho·∫∑c th·ª≠ v·ªõi v√≠ d·ª•")
        if st.button("Th·ª≠ v·ªõi video m·∫´u"):
            # Ki·ªÉm tra xem c√≥ th∆∞ m·ª•c test_videos kh√¥ng
            if os.path.exists("test_videos"):
                example_videos = [f for f in os.listdir("test_videos") if f.endswith(".mp4")]
                if example_videos:
                    # S·ª≠ d·ª•ng video ƒë·∫ßu ti√™n l√†m m·∫´u
                    example_video_path = os.path.join("test_videos", example_videos[0])
                    with open(example_video_path, 'rb') as f:
                        example_video_bytes = f.read()
                    
                    st.video(example_video_bytes)
                    
                    with st.spinner("ƒêang x·ª≠ l√Ω video m·∫´u..."):
                        # T·∫°o file t·∫°m t·ª´ video m·∫´u
                        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                        tfile.write(example_video_bytes)
                        tfile.close()
                        
                        # T·∫°o ƒë·ªëi t∆∞·ª£ng file t∆∞∆°ng t·ª± nh∆∞ uploaded_file
                        import io
                        from streamlit.runtime.uploaded_file_manager import UploadedFile
                        
                        class MockUploadedFile:
                            def __init__(self, path):
                                self.path = path
                            
                            def read(self):
                                with open(self.path, 'rb') as f:
                                    return f.read()
                        
                        mock_uploaded_file = MockUploadedFile(tfile.name)
                        
                        # Hi·ªÉn th·ªã thanh ti·∫øn ƒë·ªô
                        progress_bar = st.progress(0)
                        
                        def update_progress(progress):
                            progress_bar.progress(progress)
                        
                        # X·ª≠ l√Ω video m·∫´u
                        processed_video_path = process_video(mock_uploaded_file, config, update_progress)
                        
                        # X√≥a file t·∫°m
                        os.unlink(tfile.name)
                        
                        if processed_video_path:
                            # L∆∞u ƒë∆∞·ªùng d·∫´n v√†o session state
                            st.session_state.processed_video_path = processed_video_path
                            st.success("X·ª≠ l√Ω video m·∫´u th√†nh c√¥ng!")
                        else:
                            st.error("Kh√¥ng th·ªÉ x·ª≠ l√Ω video m·∫´u.")
                else:
                    st.error("Kh√¥ng t√¨m th·∫•y video m·∫´u trong th∆∞ m·ª•c 'test_videos'")
            else:
                st.error("Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'test_videos'")
    
    with col2:
        st.header("K·∫øt qu·∫£")
        
        # Ki·ªÉm tra xem ƒë√£ c√≥ video ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a
        if 'processed_video_path' in st.session_state and os.path.exists(st.session_state.processed_video_path):
            # Hi·ªÉn th·ªã video ƒë√£ x·ª≠ l√Ω
            with open(st.session_state.processed_video_path, 'rb') as f:
                st.video(f.read())
            
            # T√πy ch·ªçn t·∫£i xu·ªëng
            with open(st.session_state.processed_video_path, 'rb') as f:
                video_bytes = f.read()
            
            st.download_button(
                label="T·∫£i xu·ªëng video ƒë√£ x·ª≠ l√Ω",
                data=video_bytes,
                file_name="lane_detection_result.mp4",
                mime="video/mp4"
            )
        else:
            st.info("Video k·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã t·∫°i ƒë√¢y sau khi x·ª≠ l√Ω.")
    
    # Th√™m ph·∫ßn gi·ªõi thi·ªáu v√† h∆∞·ªõng d·∫´n ·ªü cu·ªëi trang
    st.markdown("""
    ## Gi·ªõi thi·ªáu
    
    ·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng OpenCV ƒë·ªÉ ph√°t hi·ªán l√†n ƒë∆∞·ªùng trong video. Thu·∫≠t to√°n ƒë√£ ƒë∆∞·ª£c c·∫£i ti·∫øn ƒë·ªÉ:
    
    - Ph√°t hi·ªán l√†n ƒë∆∞·ªùng tr·∫Øng v√† v√†ng th√¥ng qua l·ªçc m√†u HSL
    - X√°c ƒë·ªãnh c·∫°nh v·ªõi Canny Edge Detector
    - S·ª≠ d·ª•ng Hough Transform ƒë·ªÉ ph√°t hi·ªán ƒë∆∞·ªùng th·∫≥ng
    - T√≠nh to√°n v√† v·∫Ω l√†n ƒë∆∞·ªùng b√™n tr√°i v√† b√™n ph·∫£i
    
    ## C√°ch s·ª≠ d·ª•ng
    
    1. T·∫£i l√™n video c·ªßa b·∫°n ho·∫∑c s·ª≠ d·ª•ng video m·∫´u
    2. ƒêi·ªÅu ch·ªânh c√°c tham s·ªë ·ªü thanh b√™n tr√°i n·∫øu c·∫ßn
    3. Nh·∫•n n√∫t "X·ª≠ l√Ω video"
    4. Xem k·∫øt qu·∫£ v√† t·∫£i xu·ªëng video ƒë√£ x·ª≠ l√Ω
    
    ¬© 2025 - ·ª®ng d·ª•ng ph√°t hi·ªán l√†n ƒë∆∞·ªùng
    """)

if __name__ == "__main__":
    main()